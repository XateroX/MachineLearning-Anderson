{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anderson model of localization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameter choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L20-100-s100 \n",
      " /Users/danlo/Documents/PX319MLPhases/MachineLearning-Anderson/src/L20-100-s100 \n",
      " Keras-OhtsukiConv2D-111111\n"
     ]
    }
   ],
   "source": [
    "myseed= 111111\n",
    "width= 20\n",
    "nimages= 100\n",
    "img_sizeX= 100\n",
    "img_sizeY= img_sizeX\n",
    "\n",
    "validation_split= 0.1\n",
    "batch_size= 64\n",
    "myepochs= 20\n",
    "mylr= 0.01\n",
    "mywd= 1e-6\n",
    "\n",
    "datanameformat=\"L{0}-{1}-s{2}\"\n",
    "dataname=datanameformat.format(width,nimages,img_sizeX)\n",
    "dataname=\"L20-100-s100\"\n",
    "#datapath = '/storage/disqs/'+'ML-Data/Anderson/Images/'+dataname # SC-RTP\n",
    "datapath = '/Users/danlo/Documents/PX319MLPhases/'+'MachineLearning-Anderson/src/'+dataname\n",
    "\n",
    "methodformat=\"Keras-OhtsukiConv2D-{0}\"\n",
    "method=methodformat.format(myseed)\n",
    "print(dataname,\"\\n\",datapath,\"\\n\",method)\n",
    "\n",
    "modelname = '/'+method+'-model-'+dataname+'.h5'\n",
    "modelpath = datapath+modelname\n",
    "historyname = '/'+method+'-history-'+dataname+'.pkl'\n",
    "historypath = datapath+historyname\n",
    "\n",
    "#print(datapath,modelpath,historypath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard notebook settings\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard libraries\n",
    "import numpy as np\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "import random as rn\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "#np.random.seed(1337) # for reproducibility\n",
    "#np.random.seed(2000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow:  2.1.0 , keras:  2.3.1\n",
      "sklearn:  0.23.2\n"
     ]
    }
   ],
   "source": [
    "#machine learning libraries\n",
    "import tensorflow as tf \n",
    "import keras\n",
    "print(\"tensorflow: \",tf.__version__, \", keras: \", keras.__version__)\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(\"sklearn: \", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#special subroutines\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D\n",
    "from keras.layers import Conv1D, MaxPooling2D\n",
    "from keras.layers import AveragePooling2D, Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "\n",
    "# from tensorflow.keras.layers import Dense, Conv2D\n",
    "# from tensorflow.keras.layers import Conv1D, MaxPooling2D\n",
    "# from tensorflow.keras.layers import AveragePooling2D, Flatten\n",
    "# from tensorflow.keras.layers import Dropout\n",
    "# from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## starting the main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(myseed) # necessary for starting Numpy generated random numbers in a well-defined initial state.\n",
    "rn.seed(myseed+1) # necessary for starting core Python generated random numbers in a well-defined state.\n",
    "\n",
    "# The below is necessary in Python 3.2.3 onwards to\n",
    "# have reproducible behavior for certain hash-based operations.\n",
    "# See these references for further details:\n",
    "# https://docs.python.org/3.4/using/cmdline.html#envvar-PYTHONHASHSEED\n",
    "# https://github.com/fchollet/keras/issues/2280#issuecomment-306959926\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# Force TensorFlow to use single thread.\n",
    "# Multiple threads are a potential source of\n",
    "# non-reproducible results.\n",
    "# For further details, see: https://stackoverflow.com/questions/42022950/which-seeds-have-to-be-set-where-to-realize-100-reproducibility-of-training-res\n",
    "\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# The below tf.set_random_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see: https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "\n",
    "tf.compat.v2.random.set_seed(myseed+3)\n",
    "#tf.set_random_seed(1234)\n",
    "\n",
    "#sess = tf.compat.v2.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "#K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## reading the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,validation_split=validation_split)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(datapath,\n",
    "                                                 subset='training',\n",
    "                                                 target_size = (img_sizeX,img_sizeY),\n",
    "                                                 batch_size = batch_size, \n",
    "                                                 class_mode='categorical',\n",
    "                                                shuffle=True,seed=myseed)\n",
    "\n",
    "validation_set= train_datagen.flow_from_directory(datapath, \n",
    "                                              subset='validation', \n",
    "                                              target_size = (img_sizeX,img_sizeY),\n",
    "                                              batch_size = batch_size,\n",
    "                                              class_mode='categorical',\n",
    "                                                 shuffle=False,seed=myseed)\n",
    "\n",
    "# test_set = test_datagen.flow_from_directory('data-keras-L20-100/test_set',\n",
    "#                                             target_size = (171, 171),\n",
    "#                                             batch_size = batch_size,\n",
    "#                                             class_mode='categorical',\n",
    "#                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_labels = next(training_set)\n",
    "# Y_train, Y_labels = next(validation_set)\n",
    "# len(X_train),len(X_labels),len(Y_train),len(Y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_train_samples = training_set.samples\n",
    "num_of_test_samples = validation_set.samples\n",
    "num_classes = len(validation_set.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m--------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-390aba586944>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalidation_set\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'hsv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;31m#plt.title('y={}'.format(y[0]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'off'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    for x,y in validation_set:\n",
    "        plt.imshow(x[0],cmap='hsv')\n",
    "        #plt.title('y={}'.format(y[0]))\n",
    "        plt.axis('off')\n",
    "        break\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading the already trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model=load_model(modelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training some more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "myepochs=100\n",
    "\n",
    "# train DNN and store training info in history\n",
    "history = model.fit_generator(training_set,\n",
    "                         steps_per_epoch = training_set.samples // batch_size,\n",
    "                         epochs = myepochs,\n",
    "                         validation_data = validation_set,\n",
    "                         validation_steps = validation_set.samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.models.save_model(history,'Anderson_Ohtsuki_model_L20_500_keras_SGD_0_01_good_input_size.h5') \n",
    "model.save(modelpath) \n",
    "\n",
    "import pickle \n",
    "f=open(historypath,\"wb\")\n",
    "pickle.dump(history,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "score=model.evaluate(validation_set,verbose=1)\n",
    "\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# look into training history\n",
    "\n",
    "# summarize history for accuracy\n",
    "fig=plt.figure()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.ylabel('model accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.title(dataname)\n",
    "plt.show()\n",
    "fig.savefig(datapath+'/'+dataname+'_accuracy'+'.png')\n",
    "\n",
    "# summarize history for loss\n",
    "fig=plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('model loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.title(dataname)\n",
    "plt.show()\n",
    "fig.savefig(datapath+'/'+dataname+'_loss'+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set.reset()\n",
    "label=validation_set.class_indices.keys()\n",
    "\n",
    "#Confusion Matrix \n",
    "Y_pred = model.predict_generator(validation_set, num_of_test_samples // batch_size+1, verbose=1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "#basic confusion matrix\n",
    "confusion_matrix(validation_set.classes, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../PyCode/')\n",
    "from plot_confusion_matrix import *\n",
    "\n",
    "print(plot_confusion_matrix(confusion_matrix(validation_set.classes, y_pred),\n",
    "                          label,\n",
    "                          title='Confusion matrix for '+dataname,\n",
    "                          cmap=None,\n",
    "                          normalize=True))\n",
    "os.chdir('../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
